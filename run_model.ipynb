{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection on Social Media Conversations with BERT\n",
    "This notebook will show you how to implement a sarcasm classification model with BERT.\n",
    "\n",
    "We wanted to call this model DilBERT. We know how you feel... \n",
    "![alt text](data/sarcastic.gif)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Make sure you git clone the bert repo inside the root of this repo, and have all the libraries references in environment.yml installed. The syspath addition here will make sure all import references within the BERT repo work.\n",
    "\n",
    "Ideally dont reload imports, but its good if we want to play around with some defaults which we generally don't touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not 'bert_repo' in sys.path:\n",
    "    sys.path += ['bert_repo']\n",
    "    \n",
    "import importlib\n",
    "import preprocess\n",
    "importlib.reload(preprocess)\n",
    "from preprocess import load_data, standard_loader\n",
    "import model\n",
    "importlib.reload(model)\n",
    "from model import SarcasmBertBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Data loaded can either be twitter, reddit data or both. We can consider all sentences in context or just the most recent context sentence. We can also consider processing emojis to their literal text translation. Emprically, this hasnt helped.  \n",
    "\n",
    "Another potential improvement is to use a better tokenizer which can recognize misspelling and emojis as part of the tokenization process. This is suggested in the baseline paper. \n",
    "\n",
    "## Model\n",
    "The addition of extra layers to the model is defined in ```SarcasmBertBasic.create_model()```. \n",
    "The general structure of the code follows the estimator design pattern. This [paper](https://arxiv.org/abs/1708.02637) articulates best why this is an effective way to develop models.  \n",
    "\n",
    "```SarcasmBertBasic.fit()``` implements processing the data into what BERT expects using an input_fn builder, the estimator which is finally used to finetune the model, and all the bells and whistles to store models to a local checkpoint. The official [kernel](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb?hl=fr) explains these steps fairly well.  \n",
    "\n",
    "```SarcasmBertBasic.predict()``` implements taking the trained estimator and generating predictions  \n",
    "\n",
    "## Tuning\n",
    "Since BERT finetuning allows all weights of the Base model to be altered, it is prone to [catastrophic forgetting](https://arxiv.org/pdf/1905.05583.pdf), and we stick to the hyperparameter recommendations made by the BERT authors, after facing a few catastorphes ourselves. In our experiment with this dataset we found it most useful to increase Max Sequence Length to 512, keeping the recommended batch size. Number of Epochs seems to be the tuning parameter that really yields the most value in tuning.  \n",
    "\n",
    "## Hardware\n",
    "This was trained on a V100 GPU on Google Cloud - #Credits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Init\n",
      "***** Model output directory: bert_out_files/v1subtest *****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Train\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_out_files/v1subtest', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0e94035c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_out_files/v1subtest', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0e94035c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user because life will go on , you cannot repeat past events . the future is a mystery , nobody knows . whereas the past is only memories that should be taken as a lesson . lessons mean to be able to live more meaningful . the past will also be a story for poster ##ity need the money [SEP] # who _ am _ i born in japan . after high school , i made my rock band debut . i then founded a fashion ec ‘ z ##oz ##oto ##wn ’ . ts ##e - listed and gained a market worth of us $ 15 billion . in sept . 2019 , i sold it to soft ##bank group and stepped down as [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user because life will go on , you cannot repeat past events . the future is a mystery , nobody knows . whereas the past is only memories that should be taken as a lesson . lessons mean to be able to live more meaningful . the past will also be a story for poster ##ity need the money [SEP] # who _ am _ i born in japan . after high school , i made my rock band debut . i then founded a fashion ec ‘ z ##oz ##oto ##wn ’ . ts ##e - listed and gained a market worth of us $ 15 billion . in sept . 2019 , i sold it to soft ##bank group and stepped down as [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 2138 2166 2097 2175 2006 1010 2017 3685 9377 2627 2824 1012 1996 2925 2003 1037 6547 1010 6343 4282 1012 6168 1996 2627 2003 2069 5758 2008 2323 2022 2579 2004 1037 10800 1012 8220 2812 2000 2022 2583 2000 2444 2062 15902 1012 1996 2627 2097 2036 2022 1037 2466 2005 13082 3012 2342 1996 2769 102 1001 2040 1035 2572 1035 1045 2141 1999 2900 1012 2044 2152 2082 1010 1045 2081 2026 2600 2316 2834 1012 1045 2059 2631 1037 4827 14925 1520 1062 18153 11439 7962 1521 1012 24529 2063 1011 3205 1998 4227 1037 3006 4276 1997 2149 1002 2321 4551 1012 1999 17419 1012 10476 1010 1045 2853 2009 2000 3730 9299 2177 1998 3706 2091 2004 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 2138 2166 2097 2175 2006 1010 2017 3685 9377 2627 2824 1012 1996 2925 2003 1037 6547 1010 6343 4282 1012 6168 1996 2627 2003 2069 5758 2008 2323 2022 2579 2004 1037 10800 1012 8220 2812 2000 2022 2583 2000 2444 2062 15902 1012 1996 2627 2097 2036 2022 1037 2466 2005 13082 3012 2342 1996 2769 102 1001 2040 1035 2572 1035 1045 2141 1999 2900 1012 2044 2152 2082 1010 1045 2081 2026 2600 2316 2834 1012 1045 2059 2631 1037 4827 14925 1520 1062 18153 11439 7962 1521 1012 24529 2063 1011 3205 1998 4227 1037 3006 4276 1997 2149 1002 2321 4551 1012 1999 17419 1012 10476 1010 1045 2853 2009 2000 3730 9299 2177 1998 3706 2091 2004 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user word ##press fan here too # interiors ##cha ##t - it also gives me a real sense of accomplishment , to have created the site and built it up from scratch [SEP] a ##4 . blog ##ging is more relevant than ever . it gives you a platform to showcase your knowledge and skills . it has massive potential to grow your email list , improve your seo and get more clients on auto ##pi ##lot . # interiors ##cha ##t < ur ##l > @ user i hope it ’ s still relevant . we control our own little space there . if ins ##tagram goes down then where would we be ? ! i still get visitors and i ’ [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user word ##press fan here too # interiors ##cha ##t - it also gives me a real sense of accomplishment , to have created the site and built it up from scratch [SEP] a ##4 . blog ##ging is more relevant than ever . it gives you a platform to showcase your knowledge and skills . it has massive potential to grow your email list , improve your seo and get more clients on auto ##pi ##lot . # interiors ##cha ##t < ur ##l > @ user i hope it ’ s still relevant . we control our own little space there . if ins ##tagram goes down then where would we be ? ! i still get visitors and i ’ [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2773 20110 5470 2182 2205 1001 20769 7507 2102 1011 2009 2036 3957 2033 1037 2613 3168 1997 24718 1010 2000 2031 2580 1996 2609 1998 2328 2009 2039 2013 11969 102 1037 2549 1012 9927 4726 2003 2062 7882 2084 2412 1012 2009 3957 2017 1037 4132 2000 13398 2115 3716 1998 4813 1012 2009 2038 5294 4022 2000 4982 2115 10373 2862 1010 5335 2115 27457 1998 2131 2062 7846 2006 8285 8197 10994 1012 1001 20769 7507 2102 1026 24471 2140 1028 1030 5310 1045 3246 2009 1521 1055 2145 7882 1012 2057 2491 2256 2219 2210 2686 2045 1012 2065 16021 23091 3632 2091 2059 2073 2052 2057 2022 1029 999 1045 2145 2131 5731 1998 1045 1521 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2773 20110 5470 2182 2205 1001 20769 7507 2102 1011 2009 2036 3957 2033 1037 2613 3168 1997 24718 1010 2000 2031 2580 1996 2609 1998 2328 2009 2039 2013 11969 102 1037 2549 1012 9927 4726 2003 2062 7882 2084 2412 1012 2009 3957 2017 1037 4132 2000 13398 2115 3716 1998 4813 1012 2009 2038 5294 4022 2000 4982 2115 10373 2862 1010 5335 2115 27457 1998 2131 2062 7846 2006 8285 8197 10994 1012 1001 20769 7507 2102 1026 24471 2140 1028 1030 5310 1045 3246 2009 1521 1055 2145 7882 1012 2057 2491 2256 2219 2210 2686 2045 1012 2065 16021 23091 3632 2091 2059 2073 2052 2057 2022 1029 999 1045 2145 2131 5731 1998 1045 1521 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user they are also banning free movement of citizens from certain european countries . [SEP] @ user it has been passed . the bu ##rka has now been banned . the tide is turning . thank you trump @ user that ##s fabulous steve . great news to wake up to . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user they are also banning free movement of citizens from certain european countries . [SEP] @ user it has been passed . the bu ##rka has now been banned . the tide is turning . thank you trump @ user that ##s fabulous steve . great news to wake up to . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 2027 2024 2036 21029 2489 2929 1997 4480 2013 3056 2647 3032 1012 102 1030 5310 2009 2038 2042 2979 1012 1996 20934 22379 2038 2085 2042 7917 1012 1996 10401 2003 3810 1012 4067 2017 8398 1030 5310 2008 2015 18783 3889 1012 2307 2739 2000 5256 2039 2000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 2027 2024 2036 21029 2489 2929 1997 4480 2013 3056 2647 3032 1012 102 1030 5310 2009 2038 2042 2979 1012 1996 20934 22379 2038 2085 2042 7917 1012 1996 10401 2003 3810 1012 4067 2017 8398 1030 5310 2008 2015 18783 3889 1012 2307 2739 2000 5256 2039 2000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user yu ##m ! i bet tom will be very excited . your human spoil ##s you so much # lucky [SEP] @ user some pal ##s i ain ’ t seen much of at all recently @ user & @ user sum ##eti ##mes ho ##oman ##s just get so bi ##zzy . @ user @ user @ user i know dug ##al been super busy . hopefully he be back soon ! @ user @ user @ user dug ##al ’ s family has soo ##o many things going on , , they are super human ! ! ! @ user @ user @ user they are soo ##per smart family too . maybe j ##s got exams & [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user yu ##m ! i bet tom will be very excited . your human spoil ##s you so much # lucky [SEP] @ user some pal ##s i ain ’ t seen much of at all recently @ user & @ user sum ##eti ##mes ho ##oman ##s just get so bi ##zzy . @ user @ user @ user i know dug ##al been super busy . hopefully he be back soon ! @ user @ user @ user dug ##al ’ s family has soo ##o many things going on , , they are super human ! ! ! @ user @ user @ user they are soo ##per smart family too . maybe j ##s got exams & [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 9805 2213 999 1045 6655 3419 2097 2022 2200 7568 1012 2115 2529 27594 2015 2017 2061 2172 1001 5341 102 1030 5310 2070 14412 2015 1045 7110 1521 1056 2464 2172 1997 2012 2035 3728 1030 5310 1004 1030 5310 7680 20624 7834 7570 20778 2015 2074 2131 2061 12170 28753 1012 1030 5310 1030 5310 1030 5310 1045 2113 8655 2389 2042 3565 5697 1012 11504 2002 2022 2067 2574 999 1030 5310 1030 5310 1030 5310 8655 2389 1521 1055 2155 2038 17111 2080 2116 2477 2183 2006 1010 1010 2027 2024 3565 2529 999 999 999 1030 5310 1030 5310 1030 5310 2027 2024 17111 4842 6047 2155 2205 1012 2672 1046 2015 2288 13869 1004 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 9805 2213 999 1045 6655 3419 2097 2022 2200 7568 1012 2115 2529 27594 2015 2017 2061 2172 1001 5341 102 1030 5310 2070 14412 2015 1045 7110 1521 1056 2464 2172 1997 2012 2035 3728 1030 5310 1004 1030 5310 7680 20624 7834 7570 20778 2015 2074 2131 2061 12170 28753 1012 1030 5310 1030 5310 1030 5310 1045 2113 8655 2389 2042 3565 5697 1012 11504 2002 2022 2067 2574 999 1030 5310 1030 5310 1030 5310 8655 2389 1521 1055 2155 2038 17111 2080 2116 2477 2183 2006 1010 1010 2027 2024 3565 2529 999 999 999 1030 5310 1030 5310 1030 5310 2027 2024 17111 4842 6047 2155 2205 1012 2672 1046 2015 2288 13869 1004 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user i # pray all go this route including the great \" pillars \" of our community such as doctors , nurses & social workers who all too often assault , swear at , and hum ##ilia ##te the vulnerable . may the heart of # christ , not the \" heart \" of the church be upon us all ! ezekiel [SEP] may today be the day we ' re all unified by the of # christ # jesus . may today be the day his spirit of for all guides us up , up & away toward the promised land perhaps one day very soon ! e ##zek . 36 : 26 & col . 3 : 14 @ user see mr . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user i # pray all go this route including the great \" pillars \" of our community such as doctors , nurses & social workers who all too often assault , swear at , and hum ##ilia ##te the vulnerable . may the heart of # christ , not the \" heart \" of the church be upon us all ! ezekiel [SEP] may today be the day we ' re all unified by the of # christ # jesus . may today be the day his spirit of for all guides us up , up & away toward the promised land perhaps one day very soon ! e ##zek . 36 : 26 & col . 3 : 14 @ user see mr . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1045 1001 11839 2035 2175 2023 2799 2164 1996 2307 1000 13766 1000 1997 2256 2451 2107 2004 7435 1010 11500 1004 2591 3667 2040 2035 2205 2411 6101 1010 8415 2012 1010 1998 14910 27861 2618 1996 8211 1012 2089 1996 2540 1997 1001 4828 1010 2025 1996 1000 2540 1000 1997 1996 2277 2022 2588 2149 2035 999 28743 102 2089 2651 2022 1996 2154 2057 1005 2128 2035 10562 2011 1996 1997 1001 4828 1001 4441 1012 2089 2651 2022 1996 2154 2010 4382 1997 2005 2035 12468 2149 2039 1010 2039 1004 2185 2646 1996 5763 2455 3383 2028 2154 2200 2574 999 1041 24506 1012 4029 1024 2656 1004 8902 1012 1017 1024 2403 1030 5310 2156 2720 1012 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1045 1001 11839 2035 2175 2023 2799 2164 1996 2307 1000 13766 1000 1997 2256 2451 2107 2004 7435 1010 11500 1004 2591 3667 2040 2035 2205 2411 6101 1010 8415 2012 1010 1998 14910 27861 2618 1996 8211 1012 2089 1996 2540 1997 1001 4828 1010 2025 1996 1000 2540 1000 1997 1996 2277 2022 2588 2149 2035 999 28743 102 2089 2651 2022 1996 2154 2057 1005 2128 2035 10562 2011 1996 1997 1001 4828 1001 4441 1012 2089 2651 2022 1996 2154 2010 4382 1997 2005 2035 12468 2149 2039 1010 2039 1004 2185 2646 1996 5763 2455 3383 2028 2154 2200 2574 999 1041 24506 1012 4029 1024 2656 1004 8902 1012 1017 1024 2403 1030 5310 2156 2720 1012 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Started training at 2020-03-15 07:11:27.349532 *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num steps = 375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Finished training at 2020-03-15 07:11:27.363194 *****\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data\")\n",
    "train, test = load_data(load_fn=standard_loader('twitter'), context_extent='all', split=0.2)\n",
    "print(\"Init\")\n",
    "cfg = {\n",
    "    'model_ver': 'v1subtest',\n",
    "    'BERT_MODEL': 'uncased_L-12_H-768_A-12',\n",
    "    'NUM_TRAIN_EPOCHS': 3.0,\n",
    "}\n",
    "m = SarcasmBertBasic(cfg)\n",
    "print(\"Begin Train\")\n",
    "m.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user okay . i was just having a little humor but thanks so much for correct ##ing me . it really made my day . [SEP] blah blah blah . just listen to this guy . he says nothing . it ’ s all b ##lab ##ber . < ur ##l > @ user i am very confused . how does president trump undo something obama did , when obama never did anything ? very confusing johnny , very , very , very confusing . you make good ke ##tch ##up though < ur ##l > @ user @ user he has nothing to do with making ke ##tch ##up . his wife inherited 4 % from her late husband & sold it [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user okay . i was just having a little humor but thanks so much for correct ##ing me . it really made my day . [SEP] blah blah blah . just listen to this guy . he says nothing . it ’ s all b ##lab ##ber . < ur ##l > @ user i am very confused . how does president trump undo something obama did , when obama never did anything ? very confusing johnny , very , very , very confusing . you make good ke ##tch ##up though < ur ##l > @ user @ user he has nothing to do with making ke ##tch ##up . his wife inherited 4 % from her late husband & sold it [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 3100 1012 1045 2001 2074 2383 1037 2210 8562 2021 4283 2061 2172 2005 6149 2075 2033 1012 2009 2428 2081 2026 2154 1012 102 27984 27984 27984 1012 2074 4952 2000 2023 3124 1012 2002 2758 2498 1012 2009 1521 1055 2035 1038 20470 5677 1012 1026 24471 2140 1028 1030 5310 1045 2572 2200 5457 1012 2129 2515 2343 8398 25672 2242 8112 2106 1010 2043 8112 2196 2106 2505 1029 2200 16801 5206 1010 2200 1010 2200 1010 2200 16801 1012 2017 2191 2204 17710 10649 6279 2295 1026 24471 2140 1028 1030 5310 1030 5310 2002 2038 2498 2000 2079 2007 2437 17710 10649 6279 1012 2010 2564 7900 1018 1003 2013 2014 2397 3129 1004 2853 2009 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 3100 1012 1045 2001 2074 2383 1037 2210 8562 2021 4283 2061 2172 2005 6149 2075 2033 1012 2009 2428 2081 2026 2154 1012 102 27984 27984 27984 1012 2074 4952 2000 2023 3124 1012 2002 2758 2498 1012 2009 1521 1055 2035 1038 20470 5677 1012 1026 24471 2140 1028 1030 5310 1045 2572 2200 5457 1012 2129 2515 2343 8398 25672 2242 8112 2106 1010 2043 8112 2196 2106 2505 1029 2200 16801 5206 1010 2200 1010 2200 1010 2200 16801 1012 2017 2191 2204 17710 10649 6279 2295 1026 24471 2140 1028 1030 5310 1030 5310 2002 2038 2498 2000 2079 2007 2437 17710 10649 6279 1012 2010 2564 7900 1018 1003 2013 2014 2397 3129 1004 2853 2009 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user i grew up in crow ##borough . it ’ s an amazing town with amazing people , it ’ s own amazing micro ##cl ##imate , amazing countryside and it ’ s own amazing wildlife . # crow ##borough ##gi ##raf ##fe ##s [SEP] there ’ s a beautiful # wolf ##mo ##on rising over crow ##borough , east sussex this evening . nature ’ s majesty never fails to ama ##ze me . < ur ##l > @ user @ user @ user this is not true , guys ! there are no ' wild ' gi ##raf ##fe ##s in the uk [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user i grew up in crow ##borough . it ’ s an amazing town with amazing people , it ’ s own amazing micro ##cl ##imate , amazing countryside and it ’ s own amazing wildlife . # crow ##borough ##gi ##raf ##fe ##s [SEP] there ’ s a beautiful # wolf ##mo ##on rising over crow ##borough , east sussex this evening . nature ’ s majesty never fails to ama ##ze me . < ur ##l > @ user @ user @ user this is not true , guys ! there are no ' wild ' gi ##raf ##fe ##s in the uk [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 1045 3473 2039 1999 11465 10235 1012 2009 1521 1055 2019 6429 2237 2007 6429 2111 1010 2009 1521 1055 2219 6429 12702 20464 21499 1010 6429 10833 1998 2009 1521 1055 2219 6429 6870 1012 1001 11465 10235 5856 27528 7959 2015 102 2045 1521 1055 1037 3376 1001 4702 5302 2239 4803 2058 11465 10235 1010 2264 9503 2023 3944 1012 3267 1521 1055 9995 2196 11896 2000 25933 4371 2033 1012 1026 24471 2140 1028 1030 5310 1030 5310 1030 5310 2023 2003 2025 2995 1010 4364 999 2045 2024 2053 1005 3748 1005 21025 27528 7959 2015 1999 1996 2866 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 1045 3473 2039 1999 11465 10235 1012 2009 1521 1055 2019 6429 2237 2007 6429 2111 1010 2009 1521 1055 2219 6429 12702 20464 21499 1010 6429 10833 1998 2009 1521 1055 2219 6429 6870 1012 1001 11465 10235 5856 27528 7959 2015 102 2045 1521 1055 1037 3376 1001 4702 5302 2239 4803 2058 11465 10235 1010 2264 9503 2023 3944 1012 3267 1521 1055 9995 2196 11896 2000 25933 4371 2033 1012 1026 24471 2140 1028 1030 5310 1030 5310 1030 5310 2023 2003 2025 2995 1010 4364 999 2045 2024 2053 1005 3748 1005 21025 27528 7959 2015 1999 1996 2866 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] scripted tv show is not the way to a person ' s heart . still exists go seek it . < ur ##l > [SEP] # the ##bach ##elo ##r i have no idea why such beautiful women need to go on a reality tv show to find love ? seriously get out there and meet someone real its not that difficult . there are so many decent men out there who are single so don ##t put yourself through the drama which is putting your heart on a live stage in front of an audience that only cares about seeing drama ! your better than that and you deserve so much more , love is about being in the moment & finding it when you [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] scripted tv show is not the way to a person ' s heart . still exists go seek it . < ur ##l > [SEP] # the ##bach ##elo ##r i have no idea why such beautiful women need to go on a reality tv show to find love ? seriously get out there and meet someone real its not that difficult . there are so many decent men out there who are single so don ##t put yourself through the drama which is putting your heart on a live stage in front of an audience that only cares about seeing drama ! your better than that and you deserve so much more , love is about being in the moment & finding it when you [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 22892 2694 2265 2003 2025 1996 2126 2000 1037 2711 1005 1055 2540 1012 2145 6526 2175 6148 2009 1012 1026 24471 2140 1028 102 1001 1996 7693 18349 2099 1045 2031 2053 2801 2339 2107 3376 2308 2342 2000 2175 2006 1037 4507 2694 2265 2000 2424 2293 1029 5667 2131 2041 2045 1998 3113 2619 2613 2049 2025 2008 3697 1012 2045 2024 2061 2116 11519 2273 2041 2045 2040 2024 2309 2061 2123 2102 2404 4426 2083 1996 3689 2029 2003 5128 2115 2540 2006 1037 2444 2754 1999 2392 1997 2019 4378 2008 2069 14977 2055 3773 3689 999 2115 2488 2084 2008 1998 2017 10107 2061 2172 2062 1010 2293 2003 2055 2108 1999 1996 2617 1004 4531 2009 2043 2017 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 22892 2694 2265 2003 2025 1996 2126 2000 1037 2711 1005 1055 2540 1012 2145 6526 2175 6148 2009 1012 1026 24471 2140 1028 102 1001 1996 7693 18349 2099 1045 2031 2053 2801 2339 2107 3376 2308 2342 2000 2175 2006 1037 4507 2694 2265 2000 2424 2293 1029 5667 2131 2041 2045 1998 3113 2619 2613 2049 2025 2008 3697 1012 2045 2024 2061 2116 11519 2273 2041 2045 2040 2024 2309 2061 2123 2102 2404 4426 2083 1996 3689 2029 2003 5128 2115 2540 2006 1037 2444 2754 1999 2392 1997 2019 4378 2008 2069 14977 2055 3773 3689 999 2115 2488 2084 2008 1998 2017 10107 2061 2172 2062 1010 2293 2003 2055 2108 1999 1996 2617 1004 4531 2009 2043 2017 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user don ' t forget that ev ##oca ##tive sense of death when the thing decay ##s down to a black hu ##sk . art is always worth more when it makes you feel your own mortality . # total ##cr ##ap [SEP] in other news , i ' m going to take up art . [UNK] < ur ##l > @ user it ' s probably the lighting , gave the artist a special feeling when he gently slapped on the duct tape . so many meanings ! ! ! [UNK] [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user don ' t forget that ev ##oca ##tive sense of death when the thing decay ##s down to a black hu ##sk . art is always worth more when it makes you feel your own mortality . # total ##cr ##ap [SEP] in other news , i ' m going to take up art . [UNK] < ur ##l > @ user it ' s probably the lighting , gave the artist a special feeling when he gently slapped on the duct tape . so many meanings ! ! ! [UNK] [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2123 1005 1056 5293 2008 23408 24755 6024 3168 1997 2331 2043 1996 2518 13121 2015 2091 2000 1037 2304 15876 6711 1012 2396 2003 2467 4276 2062 2043 2009 3084 2017 2514 2115 2219 13356 1012 1001 2561 26775 9331 102 1999 2060 2739 1010 1045 1005 1049 2183 2000 2202 2039 2396 1012 100 1026 24471 2140 1028 1030 5310 2009 1005 1055 2763 1996 7497 1010 2435 1996 3063 1037 2569 3110 2043 2002 5251 11159 2006 1996 23245 6823 1012 2061 2116 15383 999 999 999 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2123 1005 1056 5293 2008 23408 24755 6024 3168 1997 2331 2043 1996 2518 13121 2015 2091 2000 1037 2304 15876 6711 1012 2396 2003 2467 4276 2062 2043 2009 3084 2017 2514 2115 2219 13356 1012 1001 2561 26775 9331 102 1999 2060 2739 1010 1045 1005 1049 2183 2000 2202 2039 2396 1012 100 1026 24471 2140 1028 1030 5310 2009 1005 1055 2763 1996 7497 1010 2435 1996 3063 1037 2569 3110 2043 2002 5251 11159 2006 1996 23245 6823 1012 2061 2116 15383 999 999 999 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user it ’ s funny how there aren ’ t any of @ user and like that , you know , sitting on daddy ’ s / ’ s lap , getting hugs , . . . [UNK] [UNK] poor guys . . . [SEP] is this photo real ? if so please tell me how it makes you feel ? me disgusting doesn ’ t even start to describe this . < ur ##l > @ user what about these are they real ? and even there are worse than them . ? ? ? < ur ##l > [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user it ’ s funny how there aren ’ t any of @ user and like that , you know , sitting on daddy ’ s / ’ s lap , getting hugs , . . . [UNK] [UNK] poor guys . . . [SEP] is this photo real ? if so please tell me how it makes you feel ? me disgusting doesn ’ t even start to describe this . < ur ##l > @ user what about these are they real ? and even there are worse than them . ? ? ? < ur ##l > [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2009 1521 1055 6057 2129 2045 4995 1521 1056 2151 1997 1030 5310 1998 2066 2008 1010 2017 2113 1010 3564 2006 8600 1521 1055 1013 1521 1055 5001 1010 2893 24459 1010 1012 1012 1012 100 100 3532 4364 1012 1012 1012 102 2003 2023 6302 2613 1029 2065 2061 3531 2425 2033 2129 2009 3084 2017 2514 1029 2033 19424 2987 1521 1056 2130 2707 2000 6235 2023 1012 1026 24471 2140 1028 1030 5310 2054 2055 2122 2024 2027 2613 1029 1998 2130 2045 2024 4788 2084 2068 1012 1029 1029 1029 1026 24471 2140 1028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2009 1521 1055 6057 2129 2045 4995 1521 1056 2151 1997 1030 5310 1998 2066 2008 1010 2017 2113 1010 3564 2006 8600 1521 1055 1013 1521 1055 5001 1010 2893 24459 1010 1012 1012 1012 100 100 3532 4364 1012 1012 1012 102 2003 2023 6302 2613 1029 2065 2061 3531 2425 2033 2129 2009 3084 2017 2514 1029 2033 19424 2987 1521 1056 2130 2707 2000 6235 2023 1012 1026 24471 2140 1028 1030 5310 2054 2055 2122 2024 2027 2613 1029 1998 2130 2045 2024 4788 2084 2068 1012 1029 1029 1029 1026 24471 2140 1028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: SARCASM (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_out_files/v1subtest/model.ckpt-375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_out_files/v1subtest/model.ckpt-375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "preds = m.predict(test)\n",
    "\n",
    "y_true = [e.label for e in test]\n",
    "labels = [ 'NOT_SARCASM', 'SARCASM']\n",
    "y_pred = []\n",
    "\n",
    "# Dont try and be cute by vectorizing this. It runs out of memory. \n",
    "for p in preds:\n",
    "    log_probs = p['probabilities']\n",
    "    probs = [np.exp(e) for e in log_probs]\n",
    "    lab = labels[np.argmax(probs)]\n",
    "    y_pred.append(lab)\n",
    "    \n",
    "print(\"DONE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evauation\n",
    "Manually evaluate our model for now. We should ideally use our ```estimator.train_and_evaluate()``` to monitor at which epoch/step training and test accuracy start diverging, since performance is very sentitive to number of epochs (even between epoch 2 and 3)  \n",
    "\n",
    "Even though we see high DEV accuracies, they do drop in our test evaluation. To really evaluate the nature of our performance, we need to perform some systematic error analysis as was done in the baseline paper. Did we catch the longer sentences? Are they truly diffcult sarcastic texts? Are there many references to Named entities and world knowledge concepts? Are we doing poor on emoji filled responses. We will release such analysis on this model. \n",
    "\n",
    "## Example Misclassifications\n",
    "**Case 1: Complex reference to a player not making it to the team. Very subtle Sarcasm.**  \n",
    "response: Do you think Perez will make the 18 this year?  \n",
    "Context: Could this be the La Liga player we're going after? It's clearly the return of Victor Perez.  \n",
    "label:SARCASM  \n",
    "prediction:[0.9902841  0.00971597] NOT_SARCASM  \n",
    "  \n",
    "**Case 2: Hypothetical modificaion of sentence to mock by mimicking immediately recognized.**   \n",
    "Response: After that last match Perez is clearly no victor  \n",
    "Context: Could this be the La Liga player we're going after? It's clearly the return of Victor Perez.  \n",
    "label:SARCASM  \n",
    "prediction:[0.05655888 0.94344115]  SARCASM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.803\n",
      "\n",
      "SARCASM\n",
      "Precision:0.835920177383592\n",
      "Recall:0.754\n",
      "F1 Score:0.7928496319663513\n",
      "    \n",
      "NOT SARCASM\n",
      "Precision:0.7759562841530054\n",
      "Recall:0.852\n",
      "F1 Score:0.8122020972354624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "acc = accuracy_score(y_true,y_pred)\n",
    "prec = precision_score(y_true,y_pred,pos_label='SARCASM')\n",
    "rec = recall_score(y_true,y_pred,pos_label='SARCASM')\n",
    "f1 = f1_score(y_true,y_pred,pos_label='SARCASM')\n",
    "\n",
    "ns_prec = precision_score(y_true,y_pred,pos_label='NOT_SARCASM')\n",
    "ns_rec = recall_score(y_true,y_pred,pos_label='NOT_SARCASM')\n",
    "ns_f1 = f1_score(y_true,y_pred,pos_label='NOT_SARCASM')\n",
    "\n",
    "print( \n",
    "    \"\"\"Accuracy:{}\\n\\nSARCASM\\nPrecision:{}\\nRecall:{}\\nF1 Score:{}\n",
    "    \\nNOT SARCASM\\nPrecision:{}\\nRecall:{}\\nF1 Score:{}\"\"\".format(acc,prec,rec,f1,ns_prec,ns_rec,ns_f1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition\n",
    "Some post processing of predictions to submit our results to the CodaLab Shared task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user my 3 year old , that just finished reading nietzsche and then asked me : \" a ##yo papa why these people always trying to cancel someone on twitter , trying to pretend like that makes them better themselves ? \" . to which i replied \" id ##k \" , and he just \" cu ##z [SEP] well now that ’ s problematic af < ur ##l > @ user @ user my 5 year old . . . asked me why they are making fun of native americans . . @ user @ user @ user i will take shit that didn ' t happen for $ 100 @ user @ user @ user no . . he [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user my 3 year old , that just finished reading nietzsche and then asked me : \" a ##yo papa why these people always trying to cancel someone on twitter , trying to pretend like that makes them better themselves ? \" . to which i replied \" id ##k \" , and he just \" cu ##z [SEP] well now that ’ s problematic af < ur ##l > @ user @ user my 5 year old . . . asked me why they are making fun of native americans . . @ user @ user @ user i will take shit that didn ' t happen for $ 100 @ user @ user @ user no . . he [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 2026 1017 2095 2214 1010 2008 2074 2736 3752 28898 1998 2059 2356 2033 1024 1000 1037 7677 13008 2339 2122 2111 2467 2667 2000 17542 2619 2006 10474 1010 2667 2000 9811 2066 2008 3084 2068 2488 3209 1029 1000 1012 2000 2029 1045 3880 1000 8909 2243 1000 1010 1998 2002 2074 1000 12731 2480 102 2092 2085 2008 1521 1055 18636 21358 1026 24471 2140 1028 1030 5310 1030 5310 2026 1019 2095 2214 1012 1012 1012 2356 2033 2339 2027 2024 2437 4569 1997 3128 4841 1012 1012 1030 5310 1030 5310 1030 5310 1045 2097 2202 4485 2008 2134 1005 1056 4148 2005 1002 2531 1030 5310 1030 5310 1030 5310 2053 1012 1012 2002 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 2026 1017 2095 2214 1010 2008 2074 2736 3752 28898 1998 2059 2356 2033 1024 1000 1037 7677 13008 2339 2122 2111 2467 2667 2000 17542 2619 2006 10474 1010 2667 2000 9811 2066 2008 3084 2068 2488 3209 1029 1000 1012 2000 2029 1045 3880 1000 8909 2243 1000 1010 1998 2002 2074 1000 12731 2480 102 2092 2085 2008 1521 1055 18636 21358 1026 24471 2140 1028 1030 5310 1030 5310 2026 1019 2095 2214 1012 1012 1012 2356 2033 2339 2027 2024 2437 4569 1997 3128 4841 1012 1012 1030 5310 1030 5310 1030 5310 1045 2097 2202 4485 2008 2134 1005 1056 4148 2005 1002 2531 1030 5310 1030 5310 1030 5310 2053 1012 1012 2002 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user how many ve ##ri ##fia ##ble lies has he told now ? 15 , 000 + documented . he ' s a truth teller for sure . [SEP] last week the fake news said that a section of our powerful , under construction , southern border wall “ fell over ” , trying to make it sound terrible , except the reason was that the concrete foundation was just poured & soaking wet when big winds kicked in . quickly fixed “ forever ” . @ user the mainstream media doesn ' t report the facts ; yet , the truth is available from the current resident of 1600 pennsylvania avenue , washington d . c . ~ [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user how many ve ##ri ##fia ##ble lies has he told now ? 15 , 000 + documented . he ' s a truth teller for sure . [SEP] last week the fake news said that a section of our powerful , under construction , southern border wall “ fell over ” , trying to make it sound terrible , except the reason was that the concrete foundation was just poured & soaking wet when big winds kicked in . quickly fixed “ forever ” . @ user the mainstream media doesn ' t report the facts ; yet , the truth is available from the current resident of 1600 pennsylvania avenue , washington d . c . ~ [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2129 2116 2310 3089 22749 3468 3658 2038 2002 2409 2085 1029 2321 1010 2199 1009 8832 1012 2002 1005 1055 1037 3606 21322 2005 2469 1012 102 2197 2733 1996 8275 2739 2056 2008 1037 2930 1997 2256 3928 1010 2104 2810 1010 2670 3675 2813 1523 3062 2058 1524 1010 2667 2000 2191 2009 2614 6659 1010 3272 1996 3114 2001 2008 1996 5509 3192 2001 2074 8542 1004 22721 4954 2043 2502 7266 6476 1999 1012 2855 4964 1523 5091 1524 1012 1030 5310 1996 7731 2865 2987 1005 1056 3189 1996 8866 1025 2664 1010 1996 3606 2003 2800 2013 1996 2783 6319 1997 14883 3552 3927 1010 2899 1040 1012 1039 1012 1066 102 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2129 2116 2310 3089 22749 3468 3658 2038 2002 2409 2085 1029 2321 1010 2199 1009 8832 1012 2002 1005 1055 1037 3606 21322 2005 2469 1012 102 2197 2733 1996 8275 2739 2056 2008 1037 2930 1997 2256 3928 1010 2104 2810 1010 2670 3675 2813 1523 3062 2058 1524 1010 2667 2000 2191 2009 2614 6659 1010 3272 1996 3114 2001 2008 1996 5509 3192 2001 2074 8542 1004 22721 4954 2043 2502 7266 6476 1999 1012 2855 4964 1523 5091 1524 1012 1030 5310 1996 7731 2865 2987 1005 1056 3189 1996 8866 1025 2664 1010 1996 3606 2003 2800 2013 1996 2783 6319 1997 14883 3552 3927 1010 2899 1040 1012 1039 1012 1066 102 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user maybe doc ##s just a scrub of a coach . . . i mean to get hammered with that gold standard team [SEP] @ user let ’ s ap ##lau ##d brett when he deserves it he coached an amazing game < ur ##l > @ user @ user he did try keep ko ##rk ##ma ##z in in the 4th quarter when he was a defensive liability . and six ##ers had a shit clock violation after a time ##out . and kept ho ##rford w em ##bi ##id while clip ##pers went small ball . and scott over robinson was not very smart . but for brett ##s standards . . . < ur ##l > [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user maybe doc ##s just a scrub of a coach . . . i mean to get hammered with that gold standard team [SEP] @ user let ’ s ap ##lau ##d brett when he deserves it he coached an amazing game < ur ##l > @ user @ user he did try keep ko ##rk ##ma ##z in in the 4th quarter when he was a defensive liability . and six ##ers had a shit clock violation after a time ##out . and kept ho ##rford w em ##bi ##id while clip ##pers went small ball . and scott over robinson was not very smart . but for brett ##s standards . . . < ur ##l > [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 2672 9986 2015 2074 1037 18157 1997 1037 2873 1012 1012 1012 1045 2812 2000 2131 25756 2007 2008 2751 3115 2136 102 1030 5310 2292 1521 1055 9706 17298 2094 12049 2043 2002 17210 2009 2002 8868 2019 6429 2208 1026 24471 2140 1028 1030 5310 1030 5310 2002 2106 3046 2562 12849 8024 2863 2480 1999 1999 1996 4343 4284 2043 2002 2001 1037 5600 14000 1012 1998 2416 2545 2018 1037 4485 5119 11371 2044 1037 2051 5833 1012 1998 2921 7570 26430 1059 7861 5638 3593 2096 12528 7347 2253 2235 3608 1012 1998 3660 2058 6157 2001 2025 2200 6047 1012 2021 2005 12049 2015 4781 1012 1012 1012 1026 24471 2140 1028 102 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 2672 9986 2015 2074 1037 18157 1997 1037 2873 1012 1012 1012 1045 2812 2000 2131 25756 2007 2008 2751 3115 2136 102 1030 5310 2292 1521 1055 9706 17298 2094 12049 2043 2002 17210 2009 2002 8868 2019 6429 2208 1026 24471 2140 1028 1030 5310 1030 5310 2002 2106 3046 2562 12849 8024 2863 2480 1999 1999 1996 4343 4284 2043 2002 2001 1037 5600 14000 1012 1998 2416 2545 2018 1037 4485 5119 11371 2044 1037 2051 5833 1012 1998 2921 7570 26430 1059 7861 5638 3593 2096 12528 7347 2253 2235 3608 1012 1998 3660 2058 6157 2001 2025 2200 6047 1012 2021 2005 12049 2015 4781 1012 1012 1012 1026 24471 2140 1028 102 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user is just a cover up for the real hate inside @ user . the left in a nuts ##hell ! < ur ##l > [SEP] women generally hate this president . what ' s up with men ? @ user i ' ve hated him before he was placed in office , now i hate all his enable ##rs as much as him , you woman will save this country and our world . some of us men know that , are ok with that , admire that and will help with that . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user is just a cover up for the real hate inside @ user . the left in a nuts ##hell ! < ur ##l > [SEP] women generally hate this president . what ' s up with men ? @ user i ' ve hated him before he was placed in office , now i hate all his enable ##rs as much as him , you woman will save this country and our world . some of us men know that , are ok with that , admire that and will help with that . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2003 2074 1037 3104 2039 2005 1996 2613 5223 2503 1030 5310 1012 1996 2187 1999 1037 12264 18223 999 1026 24471 2140 1028 102 2308 3227 5223 2023 2343 1012 2054 1005 1055 2039 2007 2273 1029 1030 5310 1045 1005 2310 6283 2032 2077 2002 2001 2872 1999 2436 1010 2085 1045 5223 2035 2010 9585 2869 2004 2172 2004 2032 1010 2017 2450 2097 3828 2023 2406 1998 2256 2088 1012 2070 1997 2149 2273 2113 2008 1010 2024 7929 2007 2008 1010 19837 2008 1998 2097 2393 2007 2008 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 2003 2074 1037 3104 2039 2005 1996 2613 5223 2503 1030 5310 1012 1996 2187 1999 1037 12264 18223 999 1026 24471 2140 1028 102 2308 3227 5223 2023 2343 1012 2054 1005 1055 2039 2007 2273 1029 1030 5310 1045 1005 2310 6283 2032 2077 2002 2001 2872 1999 2436 1010 2085 1045 5223 2035 2010 9585 2869 2004 2172 2004 2032 1010 2017 2450 2097 3828 2023 2406 1998 2256 2088 1012 2070 1997 2149 2273 2113 2008 1010 2024 7929 2007 2008 1010 19837 2008 1998 2097 2393 2007 2008 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user the irony being that he even has to ask why . [SEP] dear media re ##mo ##ane ##rs , you excitedly sharing clips of ordinary br ##ex ##it voters struggling to art ##iculate themselves as well as they might on live tv proves nothing about them or the br ##ex ##it vote . it just proves you lot are petty , s ##nob ##bis ##h c * * * s . @ user when spiked claim that br ##ex ##ite ##ers knew exactly what they were voting for , it ' s quite obviously un ##tr ##ue in many cases . it ' s not s ##nob ##bery - but let ' s be honest about the fact that , [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ user @ user @ user the irony being that he even has to ask why . [SEP] dear media re ##mo ##ane ##rs , you excitedly sharing clips of ordinary br ##ex ##it voters struggling to art ##iculate themselves as well as they might on live tv proves nothing about them or the br ##ex ##it vote . it just proves you lot are petty , s ##nob ##bis ##h c * * * s . @ user when spiked claim that br ##ex ##ite ##ers knew exactly what they were voting for , it ' s quite obviously un ##tr ##ue in many cases . it ' s not s ##nob ##bery - but let ' s be honest about the fact that , [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 1996 19728 2108 2008 2002 2130 2038 2000 3198 2339 1012 102 6203 2865 2128 5302 7231 2869 1010 2017 23885 6631 15281 1997 6623 7987 10288 4183 7206 8084 2000 2396 24153 3209 2004 2092 2004 2027 2453 2006 2444 2694 16481 2498 2055 2068 2030 1996 7987 10288 4183 3789 1012 2009 2074 16481 2017 2843 2024 11612 1010 1055 25083 18477 2232 1039 1008 1008 1008 1055 1012 1030 5310 2043 25362 4366 2008 7987 10288 4221 2545 2354 3599 2054 2027 2020 6830 2005 1010 2009 1005 1055 3243 5525 4895 16344 5657 1999 2116 3572 1012 2009 1005 1055 2025 1055 25083 22509 1011 2021 2292 1005 1055 2022 7481 2055 1996 2755 2008 1010 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 5310 1030 5310 1030 5310 1996 19728 2108 2008 2002 2130 2038 2000 3198 2339 1012 102 6203 2865 2128 5302 7231 2869 1010 2017 23885 6631 15281 1997 6623 7987 10288 4183 7206 8084 2000 2396 24153 3209 2004 2092 2004 2027 2453 2006 2444 2694 16481 2498 2055 2068 2030 1996 7987 10288 4183 3789 1012 2009 2074 16481 2017 2843 2024 11612 1010 1055 25083 18477 2232 1039 1008 1008 1008 1055 1012 1030 5310 2043 25362 4366 2008 7987 10288 4221 2545 2354 3599 2054 2027 2020 6830 2005 1010 2009 1005 1055 3243 5525 4895 16344 5657 1999 2116 3572 1012 2009 1005 1055 2025 1055 25083 22509 1011 2021 2292 1005 1055 2022 7481 2055 1996 2755 2008 1010 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: NOT_SARCASM (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_out_files/v1subtest/model.ckpt-375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_out_files/v1subtest/model.ckpt-375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Generate final results for Live Test Data set\n",
    "live_test = load_data(load_fn=standard_loader('twitter_test'), context_extent='all', split=None)\n",
    "live_df = load_data(load_fn=standard_loader('twitter_test'),bert_pair_shape=False, context_extent='all',split=None)\n",
    "\n",
    "ids = live_df['id'].tolist()\n",
    "\n",
    "live_preds = m.predict(live_test)\n",
    "labels = [ 'NOT_SARCASM', 'SARCASM']\n",
    "#live_y_pred = []\n",
    "\n",
    "# Dont try and be cute by vectorizing this. It runs out of memory. \n",
    "final_res = pd.DataFrame()\n",
    "for this_id, p in zip( ids, live_preds):\n",
    "    log_probs = p['probabilities']\n",
    "    probs = [np.exp(e) for e in log_probs]\n",
    "    lab = labels[np.argmax(probs)]\n",
    "    #live_y_pred.append(lab)    \n",
    "    final_res = final_res.append({'label': lab, 'id': this_id },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answer.txt\", \"w\")\n",
    "\n",
    "for _ind, row in final_res.iterrows():\n",
    "    f.write('{},{}\\n'.format(row['id'],row['label']))\n",
    "    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
